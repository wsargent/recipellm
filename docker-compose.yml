
services:

  ############################################
  # Mealie
  ############################################  

  mealie:
    image: ghcr.io/mealie-recipes/mealie:latest 
    container_name: recipellm-mealie
    restart: always
    ports:
      - "8080:8080"
      - "9000:9000"
    deploy:
      resources:
        limits:
          memory: 1000M # 
    volumes:
      - mealie-data:/app/data/
      - "/etc/localtime:/etc/localtime:ro"
      - "/etc/timezone:/etc/timezone:ro"
    environment:
      # Set Backend ENV Variables Here
      ALLOW_SIGNUP: "true"      

  ############################################
  # MCP Server
  ############################################
  
  mcp:
    build:
      context: ./mcp
      dockerfile: Dockerfile
    container_name: recipellm-mcp
    volumes:
      - "/etc/localtime:/etc/localtime:ro"
      - "/etc/timezone:/etc/timezone:ro"
      - mcp-data:/app/data
    ports:
      - "8000:8000"
    environment:
      NTFY_SERVER: http://recipellm-ntfy
      MEALIE_BASE_URL: http://recipellm-mealie:9000
      LETTA_BASE_URL: http://recipellm-letta:8283
      RECIPELLM_MCP_SERVER_URL: http://recipellm-mcp:8000/sse/   
      # chat model to use when the chef-agent is created.
      #LETTA_CHAT_MODEL: "anthropic/claude-sonnet-4-20250514"
      LETTA_CHAT_MODEL: "google_ai/gemini-2.5-flash"
    depends_on:
      letta:
        condition: service_healthy
    restart: on-failure
    command: >
      sh -c "
        /app/.venv/bin/python /app/main.py &
        sleep 10 &&
        curl -X POST http://localhost:8000/setup &&
        wait
      "

  ############################################
  # MCP Server
  ############################################

  # Letta is an agent building framework with built-in memory/vectordb support.
  # https://docs.letta.com/quickstart/docker
  letta:
    image: letta/letta:0.8.17
    container_name: recipellm-letta
    ports:
      - 8283:8283
    volumes:
      - ~/.letta/.persist/pgdata:/var/lib/postgresql/data      
    environment:
      LETTA_DEBUG: "${LETTA_DEBUG:-false}"
      # https://docs.letta.com/guides/server/providers/anthropic
      ANTHROPIC_API_KEY: $ANTHROPIC_API_KEY
      # https://docs.letta.com/guides/server/providers/google
      GEMINI_API_KEY: $GEMINI_API_KEY    
      # Setting this up means we can do postgresql://letta:letta@localhost:5432/letta in Letta Desktop
      LETTA_PG_DB: ${LETTA_PG_DB:-letta}
      LETTA_PG_USER: ${LETTA_PG_USER:-letta}
      LETTA_PG_PASSWORD: ${LETTA_PG_PASSWORD:-letta}
    restart: on-failure
    healthcheck:
      test: ["CMD", "curl", "-f", "http://127.0.0.1:8283/v1/health/"]
      interval: 5s
      timeout: 5s
      retries: 18
      start_period: 1s

  ntfy:
      image: binwiederhier/ntfy:latest
      container_name: recipellm-ntfy
      restart: always
      ports:
        - "80:80"
      volumes:
        - ntfy-cache:/var/cache/ntfy
        - ntfy-data:/var/lib/ntfy
      environment:
        - NTFY_BASE_URL=http://localhost
        - NTFY_CACHE_FILE=/var/cache/ntfy/cache.db
        - NTFY_AUTH_FILE=/var/lib/ntfy/user.db
        - NTFY_BEHIND_PROXY=true
        - NTFY_UPSTREAM_BASE_URL=https://ntfy.sh
      deploy:
        resources:
          limits:
            memory: 512M
      command: serve
volumes:
  mealie-data:
  mcp-data:
  ntfy-data:
  ntfy-cache: